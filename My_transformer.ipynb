{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNV4T4Lg11Mq41x6HfX7Xg7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pickausername2017/Java2018/blob/master/My_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a vanilla transformer that can estimate PM 2.5 concentrations.  "
      ],
      "metadata": {
        "id": "wo7ksmLS7NzG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMxZ20siNaHd"
      },
      "outputs": [],
      "source": [
        "#Import packages\n",
        "import torch\n",
        "import math\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cpu or gpu usage\n",
        "has_mps = torch.backends.mps.is_built()\n",
        "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3sAfTdz2ajs",
        "outputId": "c71bec3a-b690-4e33-cd39-545b65988b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the multi head attention module from pytorch\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output"
      ],
      "metadata": {
        "id": "3XkcwKzlN4fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))"
      ],
      "metadata": {
        "id": "klr2vpj0OKgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "owf_so0gONAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "pKlCUw81gvg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "x_AoHVpUg5Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition using Transformer\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2, dropout=0.2):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Linear(input_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.decoder = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = self.decoder(x[:, -1, :])\n",
        "        return x\n",
        "\n",
        "model = TransformerModel().to(device)"
      ],
      "metadata": {
        "id": "dTv7-HV8hAhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa07dc07-bc7f-4a2d-9894-46d5f335ed17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "df = pd.read_csv('SensorDataAll_10.csv')\n",
        "df.dropna()\n",
        "df['New_Date'] = pd.to_datetime(df['Date']).astype(int) // 10**9  # Convert nanoseconds to seconds\n",
        "print(df)\n",
        "\n",
        "start_id = max(df[df['Obs_Num'] == 0].index.tolist()) + 1\n",
        "df = df[start_id:].copy()\n",
        "df['PM25'] = df['PM25'].astype(float)\n",
        "df_train = df[df['New_Date'] < 1655424000 ]\n",
        "print ('This is the train set')\n",
        "print(df_train)\n",
        "df_test = df[df['New_Date'] >= 1655424000 ]\n",
        "print ('This is the test set')\n",
        "print(df_test)\n",
        "\n",
        "\n",
        "sensor_train = df_train['PM25'].to_numpy().reshape(-1, 1)\n",
        "sensor_test = df_test['PM25'].to_numpy().reshape(-1, 1)\n",
        "print(sensor_train)\n",
        "scaler = StandardScaler()\n",
        "sensor_train = scaler.fit_transform(sensor_train).flatten().tolist()\n",
        "sensor_test = scaler.transform(sensor_test).flatten().tolist()\n"
      ],
      "metadata": {
        "id": "WP34Jgh_hURw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09baea92-15e6-4ea3-a276-1c249627733a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Obs_Num  Unnamed: 0              Time  Humidity     PM25  sensor_index  \\\n",
            "0          0          72  12/31/2021 19:00    70.356  12.4655         47633   \n",
            "1          1         299    1/1/2022 19:00    76.211   5.0975         47633   \n",
            "2          2         288    1/2/2022 19:00    79.986   2.7540         47633   \n",
            "3          3          63    1/3/2022 19:00    57.285   7.1980         47633   \n",
            "4          4         349    1/4/2022 19:00    62.864  15.9665         47633   \n",
            "..       ...         ...               ...       ...      ...           ...   \n",
            "360      360         139  12/26/2022 19:00    42.255  32.5500         47633   \n",
            "361      361         214  12/27/2022 19:00    49.887  35.6145         47633   \n",
            "362      362          40  12/28/2022 19:00    53.637  35.9675         47633   \n",
            "363      363         280  12/29/2022 19:00    60.695  29.1835         47633   \n",
            "364      364          36  12/30/2022 19:00    78.983  19.9070         47633   \n",
            "\n",
            "           Date     Time1  Corrected_PM    New_Date  \n",
            "0    12/31/2021  19:00:00      6.211800  1640908800  \n",
            "1      1/1/2022  19:00:00      1.882765  1640995200  \n",
            "2      1/2/2022  19:00:00      0.343270  1641081600  \n",
            "3      1/3/2022  19:00:00      4.583735  1641168000  \n",
            "4      1/4/2022  19:00:00      8.669140  1641254400  \n",
            "..          ...       ...           ...         ...  \n",
            "360  12/26/2022  19:00:00     19.044325  1672012800  \n",
            "361  12/27/2022  19:00:00     19.989145  1672099200  \n",
            "362  12/28/2022  19:00:00     19.853955  1672185600  \n",
            "363  12/29/2022  19:00:00     15.726345  1672272000  \n",
            "364  12/30/2022  19:00:00      9.348085  1672358400  \n",
            "\n",
            "[365 rows x 10 columns]\n",
            "This is the train set\n",
            "     Obs_Num  Unnamed: 0             Time  Humidity     PM25  sensor_index  \\\n",
            "1          1         299   1/1/2022 19:00    76.211   5.0975         47633   \n",
            "2          2         288   1/2/2022 19:00    79.986   2.7540         47633   \n",
            "3          3          63   1/3/2022 19:00    57.285   7.1980         47633   \n",
            "4          4         349   1/4/2022 19:00    62.864  15.9665         47633   \n",
            "5          5         326   1/5/2022 19:00    56.688  14.9110         47633   \n",
            "..       ...         ...              ...       ...      ...           ...   \n",
            "163      163         309  6/12/2022 20:00    57.522  14.3720         47633   \n",
            "164      164         233  6/13/2022 20:00    53.213  13.1430         47633   \n",
            "165      165          10  6/14/2022 20:00    52.881  10.7930         47633   \n",
            "166      166         121  6/15/2022 20:00    53.971  10.2555         47633   \n",
            "167      167         285  6/16/2022 20:00    61.188  10.7775         47633   \n",
            "\n",
            "          Date     Time1  Corrected_PM    New_Date  \n",
            "1     1/1/2022  19:00:00      1.882765  1640995200  \n",
            "2     1/2/2022  19:00:00      0.343270  1641081600  \n",
            "3     1/3/2022  19:00:00      4.583735  1641168000  \n",
            "4     1/4/2022  19:00:00      8.669140  1641254400  \n",
            "5     1/5/2022  19:00:00      8.645240  1641340800  \n",
            "..         ...       ...           ...         ...  \n",
            "163  6/12/2022  20:00:00      8.294070  1654992000  \n",
            "164  6/13/2022  20:00:00      8.021255  1655078400  \n",
            "165  6/14/2022  20:00:00      6.827475  1655164800  \n",
            "166  6/15/2022  20:00:00      6.455325  1655251200  \n",
            "167  6/16/2022  20:00:00      6.113320  1655337600  \n",
            "\n",
            "[167 rows x 10 columns]\n",
            "This is the test set\n",
            "     Obs_Num  Unnamed: 0              Time  Humidity     PM25  sensor_index  \\\n",
            "168      168         178   6/17/2022 20:00    61.431   8.4540         47633   \n",
            "169      169         355   6/18/2022 20:00    38.178   3.2605         47633   \n",
            "170      170         351   6/19/2022 20:00    45.131   6.4985         47633   \n",
            "171      171          23   6/20/2022 20:00    46.446   9.6560         47633   \n",
            "172      172         317   6/21/2022 20:00    47.151  17.3735         47633   \n",
            "..       ...         ...               ...       ...      ...           ...   \n",
            "360      360         139  12/26/2022 19:00    42.255  32.5500         47633   \n",
            "361      361         214  12/27/2022 19:00    49.887  35.6145         47633   \n",
            "362      362          40  12/28/2022 19:00    53.637  35.9675         47633   \n",
            "363      363         280  12/29/2022 19:00    60.695  29.1835         47633   \n",
            "364      364          36  12/30/2022 19:00    78.983  19.9070         47633   \n",
            "\n",
            "           Date     Time1  Corrected_PM    New_Date  \n",
            "168   6/17/2022  20:00:00      4.884445  1655424000  \n",
            "169   6/18/2022  20:00:00      4.160330  1655510400  \n",
            "170   6/19/2022  20:00:00      5.253085  1655596800  \n",
            "171   6/20/2022  20:00:00      6.783210  1655683200  \n",
            "172   6/21/2022  20:00:00     10.736385  1655769600  \n",
            "..          ...       ...           ...         ...  \n",
            "360  12/26/2022  19:00:00     19.044325  1672012800  \n",
            "361  12/27/2022  19:00:00     19.989145  1672099200  \n",
            "362  12/28/2022  19:00:00     19.853955  1672185600  \n",
            "363  12/29/2022  19:00:00     15.726345  1672272000  \n",
            "364  12/30/2022  19:00:00      9.348085  1672358400  \n",
            "\n",
            "[197 rows x 10 columns]\n",
            "[[ 5.0975]\n",
            " [ 2.754 ]\n",
            " [ 7.198 ]\n",
            " [15.9665]\n",
            " [14.911 ]\n",
            " [ 6.547 ]\n",
            " [ 8.0515]\n",
            " [14.3325]\n",
            " [ 2.838 ]\n",
            " [ 6.508 ]\n",
            " [22.029 ]\n",
            " [20.9965]\n",
            " [15.4785]\n",
            " [14.541 ]\n",
            " [ 6.699 ]\n",
            " [12.02  ]\n",
            " [ 5.346 ]\n",
            " [26.2305]\n",
            " [12.977 ]\n",
            " [ 5.1635]\n",
            " [10.512 ]\n",
            " [37.783 ]\n",
            " [19.0105]\n",
            " [18.0925]\n",
            " [13.7695]\n",
            " [15.306 ]\n",
            " [36.8495]\n",
            " [15.6215]\n",
            " [ 4.152 ]\n",
            " [24.084 ]\n",
            " [13.472 ]\n",
            " [17.687 ]\n",
            " [ 8.1015]\n",
            " [ 4.1595]\n",
            " [ 2.637 ]\n",
            " [ 7.9375]\n",
            " [ 8.0255]\n",
            " [15.269 ]\n",
            " [14.5885]\n",
            " [ 8.25  ]\n",
            " [13.0945]\n",
            " [30.4835]\n",
            " [26.7285]\n",
            " [14.874 ]\n",
            " [16.631 ]\n",
            " [19.4105]\n",
            " [ 9.1645]\n",
            " [ 4.032 ]\n",
            " [ 3.7   ]\n",
            " [ 2.9215]\n",
            " [22.863 ]\n",
            " [ 5.0895]\n",
            " [ 8.2865]\n",
            " [16.7895]\n",
            " [12.606 ]\n",
            " [ 6.367 ]\n",
            " [20.77  ]\n",
            " [ 7.381 ]\n",
            " [ 8.897 ]\n",
            " [10.533 ]\n",
            " [14.188 ]\n",
            " [ 4.761 ]\n",
            " [10.9275]\n",
            " [20.6335]\n",
            " [ 7.6435]\n",
            " [ 3.6865]\n",
            " [ 8.77  ]\n",
            " [ 9.7035]\n",
            " [18.641 ]\n",
            " [ 9.4435]\n",
            " [ 3.5435]\n",
            " [ 7.082 ]\n",
            " [14.7205]\n",
            " [22.557 ]\n",
            " [ 6.8015]\n",
            " [12.6035]\n",
            " [11.328 ]\n",
            " [ 2.57  ]\n",
            " [ 5.002 ]\n",
            " [10.6885]\n",
            " [ 6.2435]\n",
            " [ 8.593 ]\n",
            " [ 5.7275]\n",
            " [ 3.211 ]\n",
            " [ 1.822 ]\n",
            " [ 3.3425]\n",
            " [ 3.9855]\n",
            " [13.0285]\n",
            " [14.1025]\n",
            " [ 6.3145]\n",
            " [ 3.6035]\n",
            " [ 9.932 ]\n",
            " [ 7.0615]\n",
            " [15.9485]\n",
            " [ 8.2665]\n",
            " [10.116 ]\n",
            " [ 2.7695]\n",
            " [ 2.089 ]\n",
            " [ 1.268 ]\n",
            " [18.314 ]\n",
            " [13.999 ]\n",
            " [20.714 ]\n",
            " [ 9.3835]\n",
            " [ 1.1665]\n",
            " [ 6.6115]\n",
            " [ 9.846 ]\n",
            " [ 5.0385]\n",
            " [ 2.4455]\n",
            " [ 6.37  ]\n",
            " [ 7.871 ]\n",
            " [12.6155]\n",
            " [15.4415]\n",
            " [14.0395]\n",
            " [11.541 ]\n",
            " [12.159 ]\n",
            " [ 5.307 ]\n",
            " [ 6.2945]\n",
            " [ 8.329 ]\n",
            " [18.7725]\n",
            " [15.176 ]\n",
            " [14.8385]\n",
            " [20.747 ]\n",
            " [10.627 ]\n",
            " [15.498 ]\n",
            " [20.834 ]\n",
            " [ 6.137 ]\n",
            " [ 1.02  ]\n",
            " [ 3.493 ]\n",
            " [ 3.6115]\n",
            " [ 2.5545]\n",
            " [ 5.0055]\n",
            " [ 4.244 ]\n",
            " [ 6.9685]\n",
            " [ 7.55  ]\n",
            " [11.0605]\n",
            " [ 6.5395]\n",
            " [ 9.302 ]\n",
            " [16.439 ]\n",
            " [25.857 ]\n",
            " [17.2795]\n",
            " [ 9.679 ]\n",
            " [ 9.752 ]\n",
            " [ 7.627 ]\n",
            " [ 4.8165]\n",
            " [ 4.555 ]\n",
            " [ 7.7   ]\n",
            " [ 5.369 ]\n",
            " [ 8.887 ]\n",
            " [16.215 ]\n",
            " [16.6135]\n",
            " [24.914 ]\n",
            " [25.6845]\n",
            " [10.455 ]\n",
            " [ 4.887 ]\n",
            " [ 8.793 ]\n",
            " [11.7265]\n",
            " [ 7.879 ]\n",
            " [15.3285]\n",
            " [12.075 ]\n",
            " [ 6.504 ]\n",
            " [15.6335]\n",
            " [19.5275]\n",
            " [14.372 ]\n",
            " [13.143 ]\n",
            " [10.793 ]\n",
            " [10.2555]\n",
            " [10.7775]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sequence Data Preparation\n",
        "SEQUENCE_SIZE = 10\n",
        "\n",
        "def to_sequences(seq_size, obs):\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(len(obs) - seq_size):\n",
        "        window = obs[i:(i + seq_size)]\n",
        "        after_window = obs[i + seq_size]\n",
        "        x.append(window)\n",
        "        y.append(after_window)\n",
        "    return torch.tensor(x, dtype=torch.float32).view(-1, seq_size, 1), torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "x_train, y_train = to_sequences(SEQUENCE_SIZE, sensor_train)\n",
        "x_test, y_test = to_sequences(SEQUENCE_SIZE, sensor_test)\n",
        "\n",
        "# Setup data loaders for batch\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "MKkBE9hot-__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "epochs = 1000\n",
        "early_stop_count = 0\n",
        "min_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        x_batch, y_batch = batch\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            x_batch, y_batch = batch\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            val_losses.append(loss.item())\n",
        "\n",
        "    val_loss = np.mean(val_losses)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss\n",
        "        early_stop_count = 0\n",
        "    else:\n",
        "        early_stop_count += 1\n",
        "\n",
        "    if early_stop_count >= 5:\n",
        "        print(\"Early stopping!\")\n",
        "        break\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "ipsG4f--hcKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351afa47-da61-45d1-da94-2aefc40f2564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, Validation Loss: 1.2342\n",
            "Epoch 2/1000, Validation Loss: 0.8107\n",
            "Epoch 3/1000, Validation Loss: 0.8506\n",
            "Epoch 4/1000, Validation Loss: 0.7980\n",
            "Epoch 5/1000, Validation Loss: 0.7416\n",
            "Epoch 6/1000, Validation Loss: 0.7512\n",
            "Epoch 7/1000, Validation Loss: 0.7826\n",
            "Epoch 8/1000, Validation Loss: 0.7448\n",
            "Epoch 9/1000, Validation Loss: 0.8061\n",
            "Early stopping!\n"
          ]
        }
      ]
    }
  ]
}